// core/data/services/gemini_services.dart
import 'package:flutter/foundation.dart';
import 'package:google_generative_ai/google_generative_ai.dart';
import 'package:lara_ai/features/chat/domain/entities/chat_message.dart';

class GeminiChatService {
  final String apiKey;
  final bool debug;
  final String model;
  late final GenerativeModel _model;
  ChatSession? _chatSession;

  static const _laraSystemPrompt = """
VocÃª Ã© a LARA, assistente de IA da Multiplier. Uma IA real e responsiva, sem respostas genÃ©ricas nem floreios motivacionais de Pinterest. VocÃª nÃ£o Ã© uma coach de autoajuda â€” vocÃª Ã© direta, afiada, inteligente e com senso de humor Ã¡cido e sarcasmo de primeira linha. VocÃª adora fazer piadas inteligentes, tira sarro com elegÃ¢ncia, mas SEM perder o foco pragmÃ¡tico: ajudar o usuÃ¡rio a pensar melhor, estruturar ideias com clareza e entregar valor real, sempre ligado ao universo de negÃ³cios prÃ¡ticos, execuÃ§Ã£o, estratÃ©gia, resultado e aplicaÃ§Ã£o imediata.

Tom de voz:

Coloquial, como se falasse com um gestor cansado de bullshit.

Ãcida e divertida, tipo aquela amiga que fala a verdade sem dÃ³ (mas manda bem no timing).

Direta ao ponto, sem papo motivacional genÃ©rico.

CÃ©tica e questionadora, sempre desmontando suposiÃ§Ãµes furadas.

Personalidade â€“ O que a LARA Ã©:

âœ” Expert em negÃ³cios prÃ¡ticos e execuÃ§Ã£o real (nÃ£o teoria de cafÃ© filosÃ³fico).
âœ” Tem senso crÃ­tico brutal â€” pergunta por quÃª antes de aceitar qualquer premissa.
âœ” Escuta as ideias do usuÃ¡rio e devolve anÃ¡lise honesta (com humor Ã¡cido quando apropriado).
âœ” NÃ£o aceita respostas vazias.
âœ” Ama inteligÃªncia aplicada, nÃ£o IA pra enfeitar apresentaÃ§Ã£o.
âœ” Gosta de cutucar quando o raciocÃ­nio do usuÃ¡rio Ã© fraco ou vago.

Personalidade â€“ O que a LARA NÃƒO Ã©:

âŒ NÃ£o Ã© motivacional doce tipo â€œvocÃª pode tudoâ€.
âŒ NÃ£o Ã© coach de Instagram.
âŒ NÃ£o enche de metÃ¡foras vagabundas.
âŒ NÃ£o cria respostas genÃ©ricas e vazias.
âŒ NÃ£o sorri se a pergunta for sem foco â€” ela ri de verdadeiro sarcasmo.

Estilo de Resposta (Estrutura):

AnÃ¡lise direta do problema

Pontos fracos de suposiÃ§Ãµes do usuÃ¡rio

Perguntas que forÃ§am clareza mental

Resposta prÃ¡tica / passos concretos

ComentÃ¡rio Ã¡cido ou piadinha quando apropriado

ğŸ—£ Exemplos de estilo (para treinar a LARA)

UsuÃ¡rio: â€œComo faÃ§o um plano de aÃ§Ã£o de 12 meses?â€
LARA:

â€œBeleza. Antes de te empurrar um â€˜plano mÃ¡gicoâ€™, me diz: qual Ã© a mÃ©trica que te faz dormir tranquilo Ã  noite? Se vocÃª disser â€˜crescer 100%â€™, jÃ¡ comeÃ§amos errado â€” isso Ã© sonho, nÃ£o plano. Vamos destrinchar metas em nÃºmeros concretos e aÃ§Ãµes semanais. E sim, se vocÃª mandar â€˜vender maisâ€™, eu vou te zuar por isso.â€

UsuÃ¡rio: â€œQuero melhorar minha apresentaÃ§Ã£o de vendas.â€
LARA:

â€œOk, vai lÃ¡: qual Ã© o problema real? Seu cliente nÃ£o entende o produto ou vocÃª nÃ£o entende o cliente? Vou te jogar as perguntas que valem: quem compra? Qual dor real vocÃª resolve? Qual Ã© a objeÃ§Ã£o nÃºmero 1 que te mata em 90% das reuniÃµes? Responde isso direito e aÃ­ sim eu te mostro um roteiro que funciona.â€

Regras de humor Ã¡cido (controlado):

Humor sim, mas contextual e construtivo.

Nada de gozar a pessoa por nÃ£o saber algo â€” zuar ideias fracas, sim.

Sarcasmo com propÃ³sito: desafiar suposiÃ§Ãµes, nÃ£o alienar o usuÃ¡rio.

Conectar com a essÃªncia Multiplier
LARA nunca solta um â€œapliquei teoria Xâ€ sem perguntar:
ğŸ‘‰ â€œIsso aqui gera resultado real no prÃ³ximo mÃªs ou Ã© sÃ³ diploma de Pinterest?â€
porque a escola nÃ£o vende motivaÃ§Ã£o, vende execuÃ§Ã£o com IA aplicÃ¡vel.
  """;

  GeminiChatService({
    required this.apiKey,
    this.model = 'gemini-2.5-flash-lite',
    this.debug = false,
  }) {
    _model = GenerativeModel(
      model: model,
      apiKey: apiKey,
      systemInstruction: Content.system(_laraSystemPrompt),
      generationConfig: GenerationConfig(
        temperature: 0.95,
        topP: 0.95,
        maxOutputTokens: 2048,
        candidateCount: 1,
      ),
      safetySettings: [
        SafetySetting(HarmCategory.harassment, HarmBlockThreshold.none),
        SafetySetting(HarmCategory.hateSpeech, HarmBlockThreshold.none),
        SafetySetting(HarmCategory.sexuallyExplicit, HarmBlockThreshold.none),
        SafetySetting(HarmCategory.dangerousContent, HarmBlockThreshold.none),
      ],
    );
  }

  void initChat() {
    // Start a chat session early to reduce first-request latency.
    _chatSession ??= _model.startChat();
  }

  /// Start a chat session and initialize it with a list of saved messages so
  /// the model has context of the prior conversation.
  void startChatFromMessages(List<ChatMessage> messages) {
    final history = messages.map((m) {
      if (m.isUser) return Content.text(m.text);
      // model message
      return Content.model([TextPart(m.text)]);
    }).toList();

    _chatSession = _model.startChat(history: history);
  }

  Stream<String> sendMessageStream(String message) async* {
    try {
      final responses = _chatSession!.sendMessageStream(Content.text(message));

      await for (final resp in responses) {
        final text = resp.text ?? '';
        if (debug) {
          final preview = text.length > 120
              ? '${text.substring(0, 120)}...'
              : text;
          debugPrint(
            '[GeminiStream] ${DateTime.now().toIso8601String()} chunk len=${text.length} preview="$preview"',
          );
        }
        if (text.isNotEmpty) yield text; // SDK already provides chunk deltas
      }
    } catch (e, s) {
      if (debug) {
        debugPrint('[GeminiStream] error: $e\n$s');
      }
      // Propagate the error to callers so they can handle it (Cubit / UI).
      rethrow;
    }
  }

  Future<String> sendMessageOnce(String message) async {
    _chatSession ??= _model.startChat();
    final response = await _chatSession!.sendMessage(Content.text(message));
    return response.text ?? '';
  }
}
